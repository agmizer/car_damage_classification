{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ce56e1",
   "metadata": {},
   "source": [
    "## Car Damage Detection\n",
    "\n",
    "This notebook implements YOLOv11 detection to detect types of damage on cars using bounding boxes. The dataset comes from https://cardd-ustc.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf8f26",
   "metadata": {},
   "source": [
    "### Dependency Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f691d55",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ec022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Formatting dataset for YOLO detection...\")\n",
    "\n",
    "# Create directory structure for detection\n",
    "splits = ['train', 'val', 'test']\n",
    "for split in splits:\n",
    "    os.makedirs(f'../../dataset/CarDD_YOLO_Detection/{split}/images', exist_ok=True)\n",
    "    os.makedirs(f'../../dataset/CarDD_YOLO_Detection/{split}/labels', exist_ok=True)\n",
    "\n",
    "    # Load COCO annotations\n",
    "    with open(f'../../dataset/CarDD_COCO/annotations/instances_{split}2017.json', 'r') as f:\n",
    "        split_data = json.load(f)\n",
    "\n",
    "    images = split_data['images']\n",
    "    annotations = split_data['annotations']\n",
    "    \n",
    "    # Group annotations by image_id (one image can have multiple annotations)\n",
    "    annotations_by_image = {}\n",
    "    for annotation in annotations:\n",
    "        image_id = annotation['image_id']\n",
    "        if image_id not in annotations_by_image:\n",
    "            annotations_by_image[image_id] = []\n",
    "        annotations_by_image[image_id].append(annotation)\n",
    "    \n",
    "    print(f\"\\nProcessing {split} split: {len(images)} images, {len(annotations)} annotations\")\n",
    "    \n",
    "    for image in images:\n",
    "        image_name = image['file_name']\n",
    "        image_id = image['id']\n",
    "        width = image['width']\n",
    "        height = image['height']\n",
    "        \n",
    "        # Copy image to YOLO directory\n",
    "        src_path = f'../../dataset/CarDD_COCO/{split}2017/{image_name}'\n",
    "        dst_path = f'../../dataset/CarDD_YOLO_Detection/{split}/images/{image_name}'\n",
    "        shutil.copy(src_path, dst_path)\n",
    "        \n",
    "        # Create corresponding label file\n",
    "        label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "        label_path = f'../../dataset/CarDD_YOLO_Detection/{split}/labels/{label_name}'\n",
    "        \n",
    "        # Get all annotations for this image\n",
    "        image_annotations = annotations_by_image.get(image_id, [])\n",
    "        \n",
    "        with open(label_path, 'w') as label_file:\n",
    "            for annotation in image_annotations:\n",
    "                # YOLO uses 0-indexed classes, COCO uses 1-indexed\n",
    "                class_id = annotation['category_id'] - 1\n",
    "                \n",
    "                # Get bounding box from COCO format [x, y, width, height] (top-left corner)\n",
    "                bbox = annotation['bbox']\n",
    "                x_min, y_min, bbox_width, bbox_height = bbox\n",
    "                \n",
    "                # Convert to YOLO format: [center_x, center_y, width, height] (normalized)\n",
    "                center_x = (x_min + bbox_width / 2) / width\n",
    "                center_y = (y_min + bbox_height / 2) / height\n",
    "                norm_width = bbox_width / width\n",
    "                norm_height = bbox_height / height\n",
    "                \n",
    "                # Write to label file: class_id center_x center_y width height\n",
    "                line = f\"{class_id} {center_x:.6f} {center_y:.6f} {norm_width:.6f} {norm_height:.6f}\"\n",
    "                label_file.write(line + '\\n')\n",
    "\n",
    "print(\"\\nDataset conversion complete!\")\n",
    "print(\"\\nCategory mapping (YOLO class_id: name):\")\n",
    "categories = split_data['categories']\n",
    "for cat in categories:\n",
    "    print(f\"  {cat['id'] - 1}: {cat['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5pb4ng47n2t",
   "metadata": {},
   "source": [
    "### Create YOLO Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cl3idi0cxb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YOLO dataset configuration file for detection\n",
    "import yaml\n",
    "\n",
    "dataset_config = {\n",
    "    'path': '../../dataset/CarDD_YOLO_Detection',  # Dataset root directory\n",
    "    'train': 'train/images',  # Training images\n",
    "    'val': 'val/images',      # Validation images\n",
    "    'test': 'test/images',    # Test images\n",
    "    \n",
    "    # Classes\n",
    "    'names': {\n",
    "        0: 'dent',\n",
    "        1: 'scratch',\n",
    "        2: 'crack',\n",
    "        3: 'glass shatter',\n",
    "        4: 'lamp broken',\n",
    "        5: 'tire flat'\n",
    "    }\n",
    "}\n",
    "\n",
    "config_path = '../../dataset/CarDD_YOLO_Detection/data.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"YOLO dataset configuration saved to: {config_path}\")\n",
    "print(\"\\nDataset is ready for YOLO detection training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7l1y8mw96",
   "metadata": {},
   "source": [
    "### Train YOLOv11 Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y0q53avkg6n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLOv11 detection model\n",
    "model = YOLO('yolo11n.pt')  # nano model for faster training, use yolo11s.pt, yolo11m.pt for better accuracy\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data='../../dataset/CarDD_YOLO_Detection/data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='car_damage_det',\n",
    "    project='runs/detect',\n",
    "    patience=10,  # Early stopping patience\n",
    "    save=True,\n",
    "    plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eldbmjzsc",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9xjfhr8oss",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "best_model = YOLO('runs/detect/car_damage_det/weights/best.pt')\n",
    "\n",
    "# Validate the model on the test set\n",
    "metrics = best_model.val(data='../../dataset/CarDD_YOLO_Detection/data.yaml', split='test')\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oo9fmwr2v7s",
   "metadata": {},
   "source": [
    "### Run Inference on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yle1ap6yoz9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on test images\n",
    "test_image_path = '../../dataset/CarDD_YOLO_Detection/test/images'\n",
    "\n",
    "# Predict on a batch of test images\n",
    "results = best_model.predict(\n",
    "    source=test_image_path,\n",
    "    save=True,  # Save annotated images\n",
    "    conf=0.25,  # Confidence threshold\n",
    "    project='runs/detect',\n",
    "    name='predictions',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} images\")\n",
    "print(f\"Results saved to: runs/detect/predictions\")\n",
    "\n",
    "# Display results for first image\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "pred_images = glob.glob('runs/detect/predictions/*.jpg')\n",
    "if pred_images:\n",
    "    print(\"\\nSample prediction:\")\n",
    "    display(Image(filename=pred_images[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
